{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3BCBLWEHPxeW"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anddennn/IAT360_YogaPoseDetection_CVProject/blob/main/ComputerVisionProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h1> <b> YOLO-NAS-POSE Yoga Detection Model <b> </h1></center>"
      ],
      "metadata": {
        "id": "URt4Q-TNmNDj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this youtube video as reference: https://www.youtube.com/watch?v=J83ZvWfxjoA\n",
        "\n",
        "Code snippets from video's linked google colab folder."
      ],
      "metadata": {
        "id": "f4zJQE__KpaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing required Libraries"
      ],
      "metadata": {
        "id": "rr-j-jCmaHId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade pip setuptools wheel\n",
        "# !apt-get install -y build-essential\n",
        "# !apt-get -y install libfluidsynth-dev\n",
        "\n",
        "# !pip install matplotlib-venn\n",
        "# !apt-get -qq install -y libfluidsynth1\n",
        "\n",
        "!pip install super-gradients\n",
        "!pip install -qq gdown torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrzmALoxKXZh",
        "outputId": "255b7228-b751-4eef-813a-13edd5c18afe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting super-gradients\n",
            "  Downloading super_gradients-3.7.1-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (4.67.1)\n",
            "Collecting boto3>=1.17.15 (from super-gradients)\n",
            "  Downloading boto3-1.40.59-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (4.25.1)\n",
            "Collecting Deprecated>=1.2.11 (from super-gradients)\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: scipy>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (1.16.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (3.10.0)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (5.9.5)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (2.19.0)\n",
            "Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (75.2.0)\n",
            "Collecting coverage~=5.3.1 (from super-gradients)\n",
            "  Downloading coverage-5.3.1.tar.gz (684 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.5/684.5 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torchvision>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (0.23.0+cu126)\n",
            "Collecting sphinx~=4.0.2 (from super-gradients)\n",
            "  Downloading Sphinx-4.0.3-py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting sphinx-rtd-theme (from super-gradients)\n",
            "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting torchmetrics==0.8 (from super-gradients)\n",
            "  Downloading torchmetrics-0.8.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting hydra-core>=1.2.0 (from super-gradients)\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.12/dist-packages (from super-gradients) (2.3.0)\n",
            "INFO: pip is looking at multiple versions of super-gradients to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting super-gradients\n",
            "  Downloading super_gradients-3.7.0-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading super_gradients-3.6.1-py3-none-any.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading super_gradients-3.6.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/40.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading super_gradients-3.5.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: opencv-python>=4.5.1 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (4.12.0.88)\n",
            "  Downloading super_gradients-3.4.1-py3-none-any.whl.metadata (37 kB)\n",
            "  Downloading super_gradients-3.4.0-py3-none-any.whl.metadata (37 kB)\n",
            "  Downloading super_gradients-3.3.1-py3-none-any.whl.metadata (37 kB)\n",
            "INFO: pip is still looking at multiple versions of super-gradients to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading super_gradients-3.3.0-py3-none-any.whl.metadata (37 kB)\n",
            "  Downloading super_gradients-3.2.1-py3-none-any.whl.metadata (35 kB)\n",
            "  Downloading super_gradients-3.2.0-py3-none-any.whl.metadata (35 kB)\n",
            "  Downloading super_gradients-3.1.3-py3-none-any.whl.metadata (35 kB)\n",
            "  Downloading super_gradients-3.1.2-py3-none-any.whl.metadata (35 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading super_gradients-3.1.1-py3-none-any.whl.metadata (36 kB)\n",
            "  Downloading super_gradients-3.1.0-py3-none-any.whl.metadata (36 kB)\n",
            "  Downloading super_gradients-3.0.9-py3-none-any.whl.metadata (34 kB)\n",
            "  Downloading super_gradients-3.0.8-py3-none-any.whl.metadata (32 kB)\n",
            "  Downloading super_gradients-3.0.7-py3-none-any.whl.metadata (32 kB)\n",
            "  Downloading super_gradients-3.0.6-py3-none-any.whl.metadata (30 kB)\n",
            "  Downloading super_gradients-3.0.5-py3-none-any.whl.metadata (30 kB)\n",
            "  Downloading super_gradients-3.0.4-py3-none-any.whl.metadata (30 kB)\n",
            "  Downloading super_gradients-3.0.3-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: pillow>=9.2.0 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (11.3.0)\n",
            "Collecting onnxruntime (from super-gradients)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting onnx>=1.10.1 (from super-gradients)\n",
            "  Downloading onnx-1.19.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "Collecting pip-tools>=6.4.0 (from super-gradients)\n",
            "  Downloading pip_tools-7.5.1-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting pyparsing==2.4.5 (from super-gradients)\n",
            "  Downloading pyparsing-2.4.5-py2.py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting einops==0.3.2 (from super-gradients)\n",
            "  Downloading einops-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting pycocotools==2.0.4 (from super-gradients)\n",
            "  Downloading pycocotools-2.0.4.tar.gz (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf~=3.19.0 (from super-gradients)\n",
            "  Downloading protobuf-3.19.6-py2.py3-none-any.whl.metadata (828 bytes)\n",
            "Collecting treelib==1.6.1 (from super-gradients)\n",
            "  Downloading treelib-1.6.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting termcolor==1.1.0 (from super-gradients)\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging>=20.4 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (25.0)\n",
            "Requirement already satisfied: wheel>=0.38.0 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (0.45.1)\n",
            "Requirement already satisfied: pygments>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from super-gradients) (2.19.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pycocotools==2.0.4->super-gradients) (2.0.2)\n",
            "Collecting pyDeprecate==0.3.* (from torchmetrics==0.8->super-gradients)\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.12/dist-packages (from treelib==1.6.1->super-gradients) (1.0.0)\n",
            "Collecting botocore<1.41.0,>=1.40.59 (from boto3>=1.17.15->super-gradients)\n",
            "  Downloading botocore-1.40.59-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.17.15->super-gradients)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.15.0,>=0.14.0 (from boto3>=1.17.15->super-gradients)\n",
            "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting wrapt<2,>=1.10 (from Deprecated>=1.2.11->super-gradients)\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from hydra-core>=1.2.0->super-gradients) (4.9.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.2.0->super-gradients) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.2.0->super-gradients) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.2.0->super-gradients) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.2.0->super-gradients) (0.27.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.4->super-gradients) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.4->super-gradients) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.4->super-gradients) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.4->super-gradients) (1.4.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.4->super-gradients) (2.9.0.post0)\n",
            "Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from omegaconf->super-gradients) (6.0.3)\n",
            "INFO: pip is looking at multiple versions of onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting onnx>=1.10.1 (from super-gradients)\n",
            "  Downloading onnx-1.19.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (7.0 kB)\n",
            "  Downloading onnx-1.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "  Downloading onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "  Downloading onnx-1.16.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "  Downloading onnx-1.16.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "  Downloading onnx-1.16.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "  Downloading onnx-1.15.0.tar.gz (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "INFO: pip is still looking at multiple versions of onnx to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading onnx-1.14.1.tar.gz (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading onnx-1.14.0.tar.gz (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m95.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading onnx-1.13.1.tar.gz (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading onnx-1.13.0.tar.gz (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m114.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading onnx-1.12.0.tar.gz (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.10.1->super-gradients) (4.15.0)\n",
            "Requirement already satisfied: build>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pip-tools>=6.4.0->super-gradients) (1.3.0)\n",
            "Requirement already satisfied: click>=8 in /usr/local/lib/python3.12/dist-packages (from pip-tools>=6.4.0->super-gradients) (8.3.0)\n",
            "Requirement already satisfied: pip>=22.2 in /usr/local/lib/python3.12/dist-packages (from pip-tools>=6.4.0->super-gradients) (24.1.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from pip-tools>=6.4.0->super-gradients) (1.2.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (3.1.6)\n",
            "Collecting docutils<0.18,>=0.14 (from sphinx~=4.0.2->super-gradients)\n",
            "  Downloading docutils-0.17.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (3.0.1)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (2.17.0)\n",
            "Collecting alabaster<0.8,>=0.7 (from sphinx~=4.0.2->super-gradients)\n",
            "  Downloading alabaster-0.7.16-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from sphinx~=4.0.2->super-gradients) (2.32.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.75.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->super-gradients) (3.9)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->super-gradients) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->super-gradients) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.4.1->super-gradients) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (3.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.9.0->super-gradients) (3.4.0)\n",
            "Collecting coloredlogs (from onnxruntime->super-gradients)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime->super-gradients) (25.9.23)\n",
            "INFO: pip is looking at multiple versions of sphinx-rtd-theme to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting sphinx-rtd-theme (from super-gradients)\n",
            "  Downloading sphinx_rtd_theme-3.0.1-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading sphinx_rtd_theme-3.0.0-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading sphinx_rtd_theme-2.0.0-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "  Downloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->super-gradients)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.12/dist-packages (from botocore<1.41.0,>=1.40.59->boto3>=1.17.15->super-gradients) (2.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from Jinja2>=2.3->sphinx~=4.0.2->super-gradients) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->sphinx~=4.0.2->super-gradients) (2025.10.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.9.0->super-gradients) (1.3.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime->super-gradients)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Downloading super_gradients-3.0.3-py3-none-any.whl (732 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.5/732.5 kB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.3.2-py3-none-any.whl (25 kB)\n",
            "Downloading pyparsing-2.4.5-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.0/68.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.6/408.6 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Downloading boto3-1.40.59-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pip_tools-7.5.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Sphinx-4.0.3-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m114.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alabaster-0.7.16-py3-none-any.whl (13 kB)\n",
            "Downloading botocore-1.40.59-py3-none-any.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m148.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docutils-0.17.1-py2.py3-none-any.whl (575 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.5/575.5 kB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pycocotools, termcolor, treelib, coverage, onnx\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pycocotools \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pycocotools\u001b[0m\u001b[31m\n",
            "\u001b[0m  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=1df68ac59393c3168b5b975a4e7ce3ccaa0691bd14add58e032f884334bc18cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/c1/20/700ac571eff732b51b81f9274796d96652d71fa5d7e8b32473\n",
            "  Building wheel for treelib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for treelib: filename=treelib-1.6.1-py3-none-any.whl size=18369 sha256=d7dbf6ad36121a6f72bd391ff5f5186ee2bddef1d55872b9268d7fd5770baf36\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/ed/e3/12466cffff1ddccffc7dd206d83a417dd0ad58a8f0ab5b408a\n",
            "  Building wheel for coverage (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for coverage: filename=coverage-5.3.1-py3-none-any.whl size=200577 sha256=9c24da4cf3dae7bb4e9535a3fa7b7285af04b204e35d8ff06a42613483b839ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/5b/d1/a1ce0fb7c34b5335cdcd7999e57bde7135e0cc086c339ca8cb\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for onnx (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for onnx\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for onnx\n",
            "Successfully built termcolor treelib coverage\n",
            "Failed to build pycocotools onnx\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pycocotools, onnx)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4373aa2",
        "outputId": "4c95b87e-b570-4ae7-bb28-31a73a45a0f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pycocotools==2.0.4 --global-option=\"build_ext\" --global-option=\"-I/usr/include/python3.10\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mDEPRECATION: --build-option and --global-option are deprecated. pip 24.2 will enforce this behaviour change. A possible replacement is to use --config-settings. Discussion can be found at https://github.com/pypa/pip/issues/11859\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Implying --no-binary=:all: due to the presence of --build-option / --global-option.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting pycocotools==2.0.4\n",
            "  Using cached pycocotools-2.0.4.tar.gz (106 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mTraceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 397, in resolve\n",
            "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n",
            "    return any(self)\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "                       ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 53, in _iter_built\n",
            "    candidate = func()\n",
            "                ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 185, in _make_candidate_from_link\n",
            "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 642, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 46, in prepare_distribution_metadata\n",
            "    self._prepare_build_backend(finder)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 78, in _prepare_build_backend\n",
            "    self.req.build_env.install_requirements(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/build_env.py\", line 218, in install_requirements\n",
            "    self._install_requirements(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/build_env.py\", line 278, in _install_requirements\n",
            "    call_subprocess(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/subprocess.py\", line 151, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen codecs>\", line 319, in decode\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "           ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 216, in exc_logging_wrapper\n",
            "    logger.debug(\"Exception information:\", exc_info=True)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1527, in debug\n",
            "    self._log(DEBUG, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1684, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1700, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1762, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1028, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/lib/python3.12/logging/handlers.py\", line 75, in emit\n",
            "    logging.FileHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1280, in emit\n",
            "    StreamHandler.emit(self, record)\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 1160, in emit\n",
            "    msg = self.format(record)\n",
            "          ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 999, in format\n",
            "    return fmt.format(record)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/logging.py\", line 112, in format\n",
            "    formatted = super().format(record)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 711, in format\n",
            "    record.exc_text = self.formatException(record.exc_info)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/logging/__init__.py\", line 661, in formatException\n",
            "    traceback.print_exception(ei[0], ei[1], tb, None, sio)\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 124, in print_exception\n",
            "    te = TracebackException(type(value), value, tb, limit=limit, compact=True)\n",
            "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 733, in __init__\n",
            "    self.stack = StackSummary._extract_from_extended_frame_gen(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 418, in _extract_from_extended_frame_gen\n",
            "    for f, (lineno, end_lineno, colno, end_colno) in frame_gen:\n",
            "                                                     ^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 355, in _walk_tb_with_full_positions\n",
            "    positions = _get_code_position(tb.tb_frame.f_code, tb.tb_lasti)\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/traceback.py\", line 369, in _get_code_position\n",
            "    return next(itertools.islice(positions_gen, instruction_index // 2, None))\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import Any, List, Tuple, Union\n",
        "\n",
        "# Third-party imports\n",
        "import cv2\n",
        "import gdown\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import yaml\n",
        "from IPython.display import YouTubeVideo\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Colab specific imports\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Constants\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "3_BT3x6HaFLn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import models\n",
        "from super_gradients.common.object_names import Models\n",
        "\n",
        "yolo_nas_pose = models.get(\"yolo_nas_pose_l\", pretrained_weights=\"coco_pose\").cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "3lxnfMWALE9z",
        "outputId": "8eda40ad-bb39-479c-dd08-38630dfa8870"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'super_gradients'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3402013858.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_names\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0myolo_nas_pose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolo_nas_pose_l\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"coco_pose\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'super_gradients'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Description\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L3FGskainy8v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "For preprocessing:\n",
        "- First manually sorted through the images to remove invalid data (i.e. clipart, children, non-yoga poses, etc.)\n",
        "- Added more diversity to the dataset\n",
        "- After annotation, used roboflow to normalize all data into 640x640 jpg images that are auto oriented for better performance\n",
        "- Augmented data with roboflow to mimic indoor conditions such as adding more low light data or low resolution data.\n"
      ],
      "metadata": {
        "id": "7aQjNM0hDaBb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from super_gradients.training import Trainer\n",
        "\n",
        "CHECKPOINT_DIR = 'checkpoints'\n",
        "trainer = Trainer(experiment_name='first_yn_pose_run', ckpt_root_dir=CHECKPOINT_DIR)"
      ],
      "metadata": {
        "id": "HpNoSkncPfQw",
        "outputId": "6c18630a-4642-4ad0-9b9f-df1057bb541f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'super_gradients'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3991803953.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mCHECKPOINT_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'first_yn_pose_run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_root_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'super_gradients'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading dataset"
      ],
      "metadata": {
        "id": "8baBWY6dPjiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7kHMqGVPPo1Q",
        "outputId": "0a1d37c6-7a79-442c-ad4f-382c54f4f128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "# fix path to dataset\n",
        "!cp -r \"/content/drive/MyDrive/Dataset\" \"/content/\""
      ],
      "metadata": {
        "id": "YiIr3J6rPpWk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"1OkaP72I2Cr9MhYbZuXi\")\n",
        "project = rf.workspace(\"yoga-pose-dataset\").project(\"yoga-poses-yiqyx\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"coco\")\n"
      ],
      "metadata": {
        "id": "Uyis1GKeKMgT",
        "outputId": "14ca7015-9df4-48ff-8abe-ba11d1e4b9e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.2.11-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from roboflow) (2025.10.5)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.12/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.4.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from roboflow) (11.3.0)\n",
            "Collecting pi-heif<2 (from roboflow)\n",
            "  Downloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (6.5 kB)\n",
            "Collecting pillow-avif-plugin<2 (from roboflow)\n",
            "  Downloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.32.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.12/dist-packages (from roboflow) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from roboflow) (6.0.3)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.12/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (1.3.3)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (4.60.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->roboflow) (3.2.5)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->roboflow) (3.4.4)\n",
            "Downloading roboflow-1.2.11-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pi_heif-1.1.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_avif_plugin-1.5.2-cp312-cp312-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m143.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Installing collected packages: pillow-avif-plugin, filetype, pi-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.12.0.88\n",
            "    Uninstalling opencv-python-headless-4.12.0.88:\n",
            "      Successfully uninstalled opencv-python-headless-4.12.0.88\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pi-heif-1.1.1 pillow-avif-plugin-1.5.2 roboflow-1.2.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2",
                  "idna"
                ]
              },
              "id": "141ab5a7a8b1407f8ec1b01b46ec4439"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Yoga-Poses-1 to coco:: 100%|██████████| 22700/22700 [00:00<00:00, 28941.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Yoga-Poses-1 in coco:: 100%|██████████| 662/662 [00:00<00:00, 5674.62it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get yaml file for standard coco keypoints.\n",
        "!wget https://raw.githubusercontent.com/Deci-AI/super-gradients/master/src/super_gradients/recipes/dataset_params/coco_pose_estimation_common_dataset_params.yaml"
      ],
      "metadata": {
        "id": "ljdUO37IQDer",
        "outputId": "09b35b76-c200-445c-8e94-16fff2681205",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-26 05:19:32--  https://raw.githubusercontent.com/Deci-AI/super-gradients/master/src/super_gradients/recipes/dataset_params/coco_pose_estimation_common_dataset_params.yaml\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1937 (1.9K) [text/plain]\n",
            "Saving to: ‘coco_pose_estimation_common_dataset_params.yaml’\n",
            "\n",
            "\r          coco_pose   0%[                    ]       0  --.-KB/s               \rcoco_pose_estimatio 100%[===================>]   1.89K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-26 05:19:32 (12.2 MB/s) - ‘coco_pose_estimation_common_dataset_params.yaml’ saved [1937/1937]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def open_file(file_path: str) -> Union[dict, list, None]:\n",
        "    \"\"\"\n",
        "    Opens and reads the content of a JSON or YAML file.\n",
        "\n",
        "    Parameters:\n",
        "    file_path (str): The path to the file.\n",
        "\n",
        "    Returns:\n",
        "    Union[dict, list, None]: The content of the file parsed to a dictionary or a list,\n",
        "                             or None if an error occurs.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r') as file:\n",
        "            if file_path.endswith('.json'):\n",
        "                return json.load(file)\n",
        "            elif file_path.endswith('.yaml') or file_path.endswith('.yml'):\n",
        "                return yaml.safe_load(file)\n",
        "            else:\n",
        "                raise ValueError(f'Unsupported file format: {file_path}')\n",
        "    except Exception as e:\n",
        "        print(f'An error occurred: {e}')\n",
        "        return None\n",
        "\n",
        "# Fix paths to dataset ###########\n",
        "\n",
        "annotations = open_file('/content/drive/MyDrive/Dataset/train/_annotations.coco.json')\n",
        "config = open_file('/content/drive/MyDrive/Dataset/valid/_annotations.coco.json')"
      ],
      "metadata": {
        "id": "VENnHqTzQMU2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotation File Breakdown:\n",
        "\n",
        "1. images:\n",
        "It's a dictionary where each entry maps an ID to a filename (typically an image filename). Each image in the dataset has a unique identifier, and this is a lookup between the ID and the filename.\n",
        "\n",
        "2. annotations:\n",
        "This is a list containing 6,117 items. Each item is a dictionary with details related to the annotations for a particular image.\n",
        "Each annotation contains an image_id, a list of keypoints, and num_keypoints value.\n",
        "\n",
        "3. categories:\n",
        "A list of categories for the dataset.\n",
        "Each category has a:\n",
        "- supercategory: A broader classification (like 'animal').\n",
        "- id: A unique identifier for the category.\n",
        "- name: The name of the category (e.g., 'dog', 'cat', 'sheep').\n",
        "- keypoints: A list of names for specific keypoints relevant to that category (like 'left_eye', 'right_eye', 'nose', etc.).\n",
        "- skeleton: A list of pairs, which are connections between keypoints."
      ],
      "metadata": {
        "id": "Y1Xj5N68Qs3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Plotting a sample of images\n",
        "\n",
        "def plot_random_images(data, image_base_dir=\"/content/images\"):\n",
        "    \"\"\"\n",
        "    Plots 5 random images for each category from the provided dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - data: The JSON dataset containing image, annotation, and category details.\n",
        "    - image_base_dir: The base directory where the images are located.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a dictionary to map image IDs to filenames\n",
        "    image_id_to_filename = {image['id']: image['filename'] for image in data['images']}\n",
        "\n",
        "    # Extracting image_ids for each category\n",
        "    category_image_ids = {}\n",
        "    for category in data['categories']:\n",
        "        category_id = category['id']\n",
        "        category_name = category['name']\n",
        "        category_image_ids[category_name] = [anno['image_id'] for anno in data['annotations'] if anno['category_id'] == category_id]\n",
        "\n",
        "    # Randomly select 5 image_ids for each category\n",
        "    random_selected_ids = {}\n",
        "    for category_name, ids in category_image_ids.items():\n",
        "        random_selected_ids[category_name] = random.sample(ids, min(5, len(ids)))\n",
        "\n",
        "    # Number of categories\n",
        "    num_categories = len(random_selected_ids)\n",
        "\n",
        "    # Create a figure to plot the images\n",
        "    fig, axes = plt.subplots(num_categories, 5, figsize=(20, num_categories * 3))\n",
        "    if num_categories == 1:  # If there is only one category, axes will be 1D\n",
        "        axes = [axes]\n",
        "\n",
        "    for i, (category_name, ids) in enumerate(random_selected_ids.items()):\n",
        "        for j, image_id in enumerate(ids):\n",
        "            # Get the filename using the image_id_to_filename dictionary\n",
        "            filename = image_id_to_filename.get(image_id, \"Image_Not_Found.jpg\")\n",
        "\n",
        "            # Load and plot the image\n",
        "            img_path = os.path.join(image_base_dir, filename)\n",
        "            try:\n",
        "                img = mpimg.imread(img_path)\n",
        "                axes[i][j].imshow(img)\n",
        "            except FileNotFoundError:\n",
        "                axes[i][j].imshow(np.zeros((100, 100, 3)))  # Show an empty image if file is not found\n",
        "            axes[i][j].axis('off')\n",
        "            if j == 0:\n",
        "                axes[i][j].set_title(category_name)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "3ZQwxy3BQxNe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change path for this\n",
        "plot_random_images(data=annotations, image_base_dir=\"/content/drive/MyDrive/Dataset/\")"
      ],
      "metadata": {
        "id": "Oa9zimu1ROyd",
        "outputId": "e92cdf16-42cb-4429-d3e3-6a2135d523bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'filename'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3674864418.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Change path for this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_random_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_base_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Dataset/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-954347960.py\u001b[0m in \u001b[0;36mplot_random_images\u001b[0;34m(data, image_base_dir)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Create a dictionary to map image IDs to filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mimage_id_to_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'filename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'images'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Extracting image_ids for each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'filename'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datasets & DataLoaders\n",
        "\n",
        "SuperGradients is fully compatible with PyTorch Datasets and Dataloaders, so you can use your dataloaders as is.\n",
        "\n",
        "### SuperGradients also provides you with the `AbstractPoseEstimationDataset` class.\n",
        "\n",
        "This is an abstract class defines a blueprint for datasets related to pose estimation tasks. It's expected that concrete implementations of this class will be created for specific datasets.\n",
        "\n",
        "- **Inheritance**: It inherits from PyTorch's `Dataset` and `HasPreprocessingParams`.\n",
        "\n",
        "- **Initialization**:\n",
        "  - Takes in parameters like `transforms`, `num_joints`, `edge_links`, `edge_colors`, and `keypoint_colors`.\n",
        "  - Initializes instance variables and constructs a transform pipeline (`KeypointsCompose`).\n",
        "\n",
        "- **Abstract Methods (`__len__` and `load_sample`)**:\n",
        "  - These methods are declared but don't have a concrete implementation in this class. Your derived class from this abstract class is expected to provide an implementation for these methods.\n",
        "  \n",
        "- **`load_random_sample` Method**:\n",
        "  - This method is used to fetch a random sample from the dataset. It uses the `__len__` method to get the total number of samples and then randomly selects an index to retrieve using `load_sample`.\n",
        "\n",
        "- **`__getitem__` Method**:\n",
        "  - This method retrieves a sample given its index. It then applies the defined transformations on the sample and returns it. This method is crucial for PyTorch's DataLoader to fetch samples during training.\n",
        "\n",
        "- **`get_dataset_preprocessing_params` Method**:\n",
        "  - This method defines and returns preprocessing parameters for the dataset. It seems to construct a pipeline of preprocessing steps and their parameters.\n"
      ],
      "metadata": {
        "id": "bkeI_DyoRsu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Expand this cell to see how the `AnimalPoseEstimationDataset` is implemented\n",
        "from super_gradients.common.decorators.factory_decorator import resolve_param\n",
        "from super_gradients.common.factories.target_generator_factory import TargetGeneratorsFactory\n",
        "from super_gradients.common.factories.transforms_factory import TransformsFactory\n",
        "from super_gradients.common.object_names import Datasets\n",
        "from super_gradients.common.registry import register_dataset\n",
        "from super_gradients.training.transforms.keypoint_transforms import AbstractKeypointTransform\n",
        "from super_gradients.training.samples import PoseEstimationSample\n",
        "\n",
        "from super_gradients.training.datasets.pose_estimation_datasets.abstract_pose_estimation_dataset import AbstractPoseEstimationDataset\n",
        "\n",
        "from super_gradients.training.datasets.pose_estimation_datasets import YoloNASPoseCollateFN\n",
        "\n",
        "class PoseEstimationDataset(AbstractPoseEstimationDataset):\n",
        "    \"\"\"\n",
        "    Dataset class for training pose estimation models on Animal Pose dataset.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    @resolve_param(\"transforms\", TransformsFactory())\n",
        "    def __init__(\n",
        "        self,\n",
        "        data_dir: str,\n",
        "        images_dir: str,\n",
        "        json_file: str,\n",
        "        transforms: List[AbstractKeypointTransform],\n",
        "        edge_links: Union[List[Tuple[int, int]], np.ndarray],\n",
        "        edge_colors: Union[List[Tuple[int, int, int]], np.ndarray, None],\n",
        "        keypoint_colors: Union[List[Tuple[int, int, int]], np.ndarray, None],\n",
        "    ):\n",
        "        \"\"\"\n",
        "\n",
        "        :param data_dir: Root directory of the COCO dataset\n",
        "        :param images_dir: path suffix to the images directory inside the data_dir\n",
        "        :param json_file: path suffix to the json file inside the data_dir\n",
        "        :param include_empty_samples: Not used, but exists for compatibility with COCO dataset config.\n",
        "        :param target_generator: Target generator that will be used to generate the targets for the model.\n",
        "            See DEKRTargetsGenerator for an example.\n",
        "        :param transforms: Transforms to be applied to the image & keypoints\n",
        "        \"\"\"\n",
        "        split_json_file = os.path.join(data_dir, json_file)\n",
        "\n",
        "        with open(split_json_file, \"r\") as f:\n",
        "            json_annotations = json.load(f)\n",
        "\n",
        "\n",
        "        joints = json_annotations[\"categories\"][0][\"keypoints\"]\n",
        "        num_joints = len(joints)\n",
        "\n",
        "        super().__init__(\n",
        "            transforms=transforms,\n",
        "            num_joints=num_joints,\n",
        "            edge_links=edge_links,\n",
        "            edge_colors=edge_colors,\n",
        "            keypoint_colors=keypoint_colors,\n",
        "        )\n",
        "\n",
        "        self.num_joints = num_joints\n",
        "        print(self.num_joints)\n",
        "\n",
        "\n",
        "        images_and_ids = []\n",
        "\n",
        "        for image in json_annotations[\"images\"]:\n",
        "          images_and_ids.append((image[\"id\"], os.path.join(data_dir, images_dir, image[\"filename\"])))\n",
        "        self.image_ids, self.image_files = zip(*images_and_ids)\n",
        "\n",
        "        self.annotations = []\n",
        "\n",
        "        for image_id in self.image_ids:\n",
        "            keypoints_per_image = []\n",
        "            bboxes_per_image = []\n",
        "\n",
        "            image_annotations = [ann for ann in json_annotations[\"annotations\"] if str(ann[\"image_id\"]) == str(image_id)]\n",
        "            for ann in image_annotations:\n",
        "                keypoints = np.array(ann[\"keypoints\"]).reshape(self.num_joints, 3)\n",
        "                x1, y1, x2, y2 = ann[\"bbox\"]\n",
        "\n",
        "                bbox_xywh = np.array([x1, y1, x2 - x1, y2 - y1])\n",
        "                keypoints_per_image.append(keypoints)\n",
        "                bboxes_per_image.append(bbox_xywh)\n",
        "\n",
        "            keypoints_per_image = np.array(keypoints_per_image, dtype=np.float32).reshape(-1, self.num_joints, 3)\n",
        "            bboxes_per_image = np.array(bboxes_per_image, dtype=np.float32).reshape(-1, 4)\n",
        "            annotation = keypoints_per_image, bboxes_per_image\n",
        "            self.annotations.append(annotation)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def load_sample(self, index) -> PoseEstimationSample:\n",
        "        file_path = self.image_files[index]\n",
        "        gt_joints, gt_bboxes = self.annotations[index]  # boxes in xywh format\n",
        "\n",
        "        gt_areas = np.array([box[2] * box[3] for box in gt_bboxes], dtype=np.float32)\n",
        "        gt_iscrowd = np.array([0] * len(gt_joints), dtype=bool)\n",
        "\n",
        "        image = cv2.imread(file_path, cv2.IMREAD_COLOR)\n",
        "        mask = np.ones(image.shape[:2], dtype=np.float32)\n",
        "\n",
        "        return PoseEstimationSample(\n",
        "            image=image, mask=mask, joints=gt_joints, areas=gt_areas, bboxes_xywh=gt_bboxes, is_crowd=gt_iscrowd, additional_samples=None\n",
        "        )"
      ],
      "metadata": {
        "id": "tNoeQk-zR5oB",
        "outputId": "90de667f-fea4-4029-a313-681191781059",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'super_gradients'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-633406369.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Expand this cell to see how the `AnimalPoseEstimationDataset` is implemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecorators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactory_decorator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mresolve_param\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_generator_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTargetGeneratorsFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms_factory\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTransformsFactory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_names\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'super_gradients'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories for annotated files\n",
        "\n",
        "# Change Paths\n",
        "train_annotations = open_file('/content/drive/MyDrive/Dataset/train/')\n",
        "val_annotations = open_file('/content/drive/MyDrive/Dataset/valid/')"
      ],
      "metadata": {
        "id": "uBgKq4CBR-NH",
        "outputId": "bff893d3-1e65-47c6-b386-bd092ef5a71b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'open_file' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-758084804.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Change Paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Dataset/train/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mval_annotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Dataset/valid/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'open_file' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KeyPoint Tranformations\n",
        "\n",
        "Instantiate the transformations"
      ],
      "metadata": {
        "id": "najn_WPGSHfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Expand this cell to see how the transforms are instantiated\n",
        "from super_gradients.training.transforms.keypoints import (\n",
        "    KeypointsHSV,\n",
        "    KeypointsBrightnessContrast,\n",
        "    KeypointsMosaic,\n",
        "    KeypointsRandomAffineTransform,\n",
        "    KeypointsLongestMaxSize,\n",
        "    KeypointsPadIfNeeded,\n",
        "    KeypointsImageStandardize,\n",
        "    KeypointsImageNormalize,\n",
        "    KeypointsRemoveSmallObjects\n",
        ")\n",
        "\n",
        "# Indexes of keypoints on the flipped image. When doing left-right flip, left hand becomes right hand.\n",
        "#So this array contains order of keypoints on the flipped image. This is dataset specific and depends on\n",
        "#how keypoints are defined in dataset.\n",
        "#keypoints_random_horizontal_flip = KeypointsRandomHorizontalFlip(flip_index=config['flip_indexes'], prob=0.5)\n",
        "\n",
        "keypoints_hsv = KeypointsHSV(prob=0.5, hgain=20, sgain=20, vgain=20)\n",
        "\n",
        "keypoints_brightness_contrast = KeypointsBrightnessContrast(prob=0.5,\n",
        "                                                            brightness_range=[0.8, 1.2],\n",
        "                                                            contrast_range=[0.8, 1.2]\n",
        "                                                            )\n",
        "\n",
        "keypoints_mosaic = KeypointsMosaic(prob=0.8)\n",
        "\n",
        "keypoints_random_affine_transform = KeypointsRandomAffineTransform(max_rotation=0,\n",
        "                                                                   min_scale=0.5,\n",
        "                                                                   max_scale=1.5,\n",
        "                                                                   max_translate=0.1,\n",
        "                                                                   image_pad_value=127,\n",
        "                                                                   mask_pad_value=1,\n",
        "                                                                   prob=0.75,\n",
        "                                                                   interpolation_mode=[0, 1, 2, 3, 4]\n",
        "                                                                   )\n",
        "\n",
        "keypoints_longest_max_size = KeypointsLongestMaxSize(max_height=640, max_width=640)\n",
        "\n",
        "keypoints_pad_if_needed = KeypointsPadIfNeeded(min_height=640,\n",
        "                                               min_width=640,\n",
        "                                               image_pad_value=[127, 127, 127],\n",
        "                                               mask_pad_value=1,\n",
        "                                               padding_mode='bottom_right'\n",
        "                                               )\n",
        "\n",
        "keypoints_image_standardize = KeypointsImageStandardize(max_value=255)\n",
        "\n",
        "# keypoints_image_normalize = KeypointsImageNormalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                                     std=[0.229, 0.224, 0.225]\n",
        "#                                                     )\n",
        "\n",
        "keypoints_remove_small_objects = KeypointsRemoveSmallObjects(min_instance_area=1,\n",
        "                                                             min_visible_keypoints=1\n",
        "                                                             )"
      ],
      "metadata": {
        "id": "R14hnNdBSOiu",
        "outputId": "047a41f8-032e-4528-9fb7-aa7948960040",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'super_gradients'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2075300975.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Expand this cell to see how the transforms are instantiated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m from super_gradients.training.transforms.keypoints import (\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mKeypointsHSV\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mKeypointsBrightnessContrast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mKeypointsMosaic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'super_gradients'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = [\n",
        "    keypoints_hsv,\n",
        "    keypoints_brightness_contrast,\n",
        "    keypoints_mosaic,\n",
        "    keypoints_random_affine_transform,\n",
        "    keypoints_longest_max_size,\n",
        "    keypoints_pad_if_needed,\n",
        "    keypoints_image_standardize,\n",
        "    keypoints_remove_small_objects\n",
        "]\n",
        "\n",
        "val_transforms = [\n",
        "    keypoints_longest_max_size,\n",
        "    keypoints_pad_if_needed,\n",
        "    keypoints_image_standardize,\n",
        "]"
      ],
      "metadata": {
        "id": "S6hCFEGWSc3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE FOR OUR CUSTOM DATA\n",
        "\n",
        "data_path = \"/content/drive/MyDrive/Dataset\"\n",
        "\n",
        "# Create instances of the dataset\n",
        "train_dataset = PoseEstimationDataset(\n",
        "    data_dir=data_path,\n",
        "    images_dir= data_path + '/train',\n",
        "    json_file= data_path + '/train/keypoint_train.json',\n",
        "    transforms=train_transforms,\n",
        "    edge_links = config['edge_links'],\n",
        "    edge_colors = config['edge_colors'],\n",
        "    keypoint_colors = config['keypoint_colors']\n",
        "    )\n",
        "\n",
        "val_dataset = PoseEstimationDataset(\n",
        "    data_dir='/content/drive/MyDrive/Dataset',\n",
        "    images_dir= data_path + '/val',\n",
        "    json_file= data_path + '/val/keypoint_val.json',\n",
        "    transforms=val_transforms,\n",
        "    edge_links = config['edge_links'],\n",
        "    edge_colors = config['edge_colors'],\n",
        "    keypoint_colors = config['keypoint_colors']\n",
        "    )\n",
        "\n",
        "test_dataset = PoseEstimationDataset(\n",
        "    data_dir='/content/drive/MyDrive/Dataset',\n",
        "    images_dir= data_path + '/val',\n",
        "    json_file= data_path + '/val/keypoint_val.json',\n",
        "    transforms=val_transforms,\n",
        "    edge_links = config['edge_links'],\n",
        "    edge_colors = config['edge_colors'],\n",
        "    keypoint_colors = config['keypoint_colors']\n",
        "    )"
      ],
      "metadata": {
        "id": "EIpRweKiSeXv",
        "outputId": "60a5c136-1420-4026-a7c8-daad23866422",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'PoseEstimationDataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2957469931.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create instances of the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_dataset = PoseEstimationDataset(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mimages_dir\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'PoseEstimationDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader_params = {\n",
        "    'shuffle': True,\n",
        "    'batch_size': 16,\n",
        "    'drop_last': True,\n",
        "    'pin_memory': False,\n",
        "    'collate_fn': YoloNASPoseCollateFN()\n",
        "    }\n",
        "\n",
        "val_dataloader_params = {\n",
        "    'shuffle': True,\n",
        "    'batch_size': 16,\n",
        "    'drop_last': True,\n",
        "    'pin_memory': False,\n",
        "    'collate_fn': YoloNASPoseCollateFN()\n",
        "    }\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, **train_dataloader_params)\n",
        "\n",
        "val_dataloader = DataLoader(val_dataset, **val_dataloader_params)\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset, **val_dataloader_params)"
      ],
      "metadata": {
        "id": "U-DvAqPZSo3R",
        "outputId": "5d4fd82c-235b-44e0-8e3b-d34f657ef6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'YoloNASPoseCollateFN' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-203969243.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m'drop_last'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m'pin_memory'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;34m'collate_fn'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mYoloNASPoseCollateFN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     }\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'YoloNASPoseCollateFN' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instantiate the model"
      ],
      "metadata": {
        "id": "Z4NWDZ0PSuRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_nas_pose = models.get(\"yolo_nas_pose_l\",\n",
        "                           num_classes=config['num_joints'],\n",
        "                           pretrained_weights=\"coco_pose\").cuda()"
      ],
      "metadata": {
        "id": "nDD2-jMySxAO",
        "outputId": "9e28a93a-f27c-4e65-daed-a6f5a4cd91aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'models' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-631207976.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m yolo_nas_pose = models.get(\"yolo_nas_pose_l\",\n\u001b[0m\u001b[1;32m      2\u001b[0m                            \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_joints'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                            pretrained_weights=\"coco_pose\").cuda()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training parameters"
      ],
      "metadata": {
        "id": "AF3eA3k5S5CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Expand this cell to see the training params\n",
        "from super_gradients.training.models.pose_estimation_models.yolo_nas_pose import YoloNASPosePostPredictionCallback\n",
        "from super_gradients.training.utils.callbacks import ExtremeBatchPoseEstimationVisualizationCallback, Phase\n",
        "from super_gradients.training.utils.early_stopping import EarlyStop\n",
        "from super_gradients.training.metrics import PoseEstimationMetrics\n",
        "\n",
        "# Note: after next release unwrap all lines wrapped in oc.OmegaConf.create\n",
        "import omegaconf as oc\n",
        "\n",
        "post_prediction_callback = YoloNASPosePostPredictionCallback(\n",
        "  pose_confidence_threshold = 0.01,\n",
        "  nms_iou_threshold = 0.7,\n",
        "  pre_nms_max_predictions = 300,\n",
        "  post_nms_max_predictions = 30,\n",
        ")\n",
        "\n",
        "metrics = PoseEstimationMetrics(\n",
        "  num_joints = config['num_joints'],\n",
        "  oks_sigmas = config['oks_sigmas'],\n",
        "  max_objects_per_image = 30,\n",
        "  post_prediction_callback = post_prediction_callback,\n",
        ")\n",
        "\n",
        "visualization_callback = ExtremeBatchPoseEstimationVisualizationCallback(\n",
        "  keypoint_colors = config[\"keypoint_colors\"],\n",
        "  edge_colors = config['edge_colors'],\n",
        "  edge_links = config['edge_links'],\n",
        "  loss_to_monitor = \"YoloNASPoseLoss/loss\",\n",
        "  max = True,\n",
        "  freq = 1,\n",
        "  max_images = 1,\n",
        "  enable_on_train_loader = True,\n",
        "  enable_on_valid_loader = True,\n",
        "  post_prediction_callback = post_prediction_callback,\n",
        ")\n",
        "\n",
        "early_stop = EarlyStop(\n",
        "  phase = Phase.VALIDATION_EPOCH_END,\n",
        "  monitor = \"AP\",\n",
        "  mode = \"max\",\n",
        "  min_delta = 0.0001,\n",
        "  patience = 100,\n",
        "  verbose = True,\n",
        ")\n",
        "\n",
        "train_params = {\n",
        "    \"warmup_mode\": \"LinearBatchLRWarmup\",\n",
        "    \"warmup_initial_lr\": 1e-8,\n",
        "    \"lr_warmup_epochs\": 1,\n",
        "    \"initial_lr\": 5e-5,\n",
        "    \"lr_mode\": \"cosine\",\n",
        "    \"cosine_final_lr_ratio\": 5e-3,\n",
        "    \"max_epochs\": 5,\n",
        "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
        "    \"batch_accumulate\": 1,\n",
        "    \"average_best_models\": True,\n",
        "    \"save_ckpt_epoch_list\": [5, 10, 15, 20],\n",
        "    \"loss\": \"yolo_nas_pose_loss\",\n",
        "    \"criterion_params\": {\n",
        "        \"oks_sigmas\": config['oks_sigmas'],\n",
        "        \"classification_loss_weight\": 1.0,\n",
        "        \"classification_loss_type\": \"focal\",\n",
        "        \"regression_iou_loss_type\": \"ciou\",\n",
        "        \"iou_loss_weight\": 2.5,\n",
        "        \"dfl_loss_weight\": 0.01,\n",
        "        \"pose_cls_loss_weight\": 1.0,\n",
        "        \"pose_reg_loss_weight\": 34.0,\n",
        "        \"pose_classification_loss_type\": \"focal\",\n",
        "        \"rescale_pose_loss_with_assigned_score\": True,\n",
        "        \"assigner_multiply_by_pose_oks\": True,\n",
        "    },\n",
        "    \"optimizer\": \"AdamW\",\n",
        "    \"optimizer_params\": {\n",
        "        \"weight_decay\": 0.000001\n",
        "    },\n",
        "    \"ema\": True,\n",
        "    \"ema_params\": {\n",
        "        \"decay\": 0.997,\n",
        "        \"decay_type\": \"threshold\"\n",
        "    },\n",
        "    \"mixed_precision\": True,\n",
        "    \"sync_bn\": False,\n",
        "    \"valid_metrics_list\": [metrics],\n",
        "    \"phase_callbacks\": [visualization_callback, early_stop],\n",
        "    \"pre_prediction_callback\": None,\n",
        "    \"metric_to_watch\": \"AP\",\n",
        "    \"greater_metric_to_watch_is_better\": True,\n",
        "    \"_convert_\": \"all\"\n",
        "}"
      ],
      "metadata": {
        "id": "WrzxEtOzS-9t",
        "outputId": "33791e91-d829-4a61-cbc0-bddf1bef91ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'super_gradients'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-544743097.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title Expand this cell to see the training params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpose_estimation_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myolo_nas_pose\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYoloNASPosePostPredictionCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtremeBatchPoseEstimationVisualizationCallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPhase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mearly_stopping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPoseEstimationMetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'super_gradients'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the model"
      ],
      "metadata": {
        "id": "asKFCOTaTDT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note, this is training for 10 epochs to demonstrate how to do it -> Change to fewer epochs\n",
        "trainer.train(model=yolo_nas_pose,\n",
        "              training_params=train_params,\n",
        "              train_loader=train_dataloader,\n",
        "              valid_loader=val_dataloader\n",
        "              )"
      ],
      "metadata": {
        "id": "mRJU8A5gTFOf",
        "outputId": "fef8572d-3815-44c2-ea8c-297b6cbab43b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1199108139.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Note, this is training for 10 epochs to demonstrate how to do it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m trainer.train(model=yolo_nas_pose,\n\u001b[0m\u001b[1;32m      3\u001b[0m               \u001b[0mtraining_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mvalid_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the best trained model"
      ],
      "metadata": {
        "id": "SSu42NXRTTqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = models.get('yolo_nas_pose_l',\n",
        "                        num_classes=config['num_joints'],\n",
        "                        checkpoint_path=\"/content/checkpoints/first_yn_pose_run/RUN_20240205_192025_039799/ckpt_best.pth\")"
      ],
      "metadata": {
        "id": "5crEDfmgTVk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the best trained model"
      ],
      "metadata": {
        "id": "rayiVUzfTbTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "post_prediction_callback = YoloNASPosePostPredictionCallback(\n",
        "  pose_confidence_threshold = 0.01,\n",
        "  nms_iou_threshold = 0.7,\n",
        "  pre_nms_max_predictions = 300,\n",
        "  post_nms_max_predictions = 30,\n",
        ")\n",
        "\n",
        "metrics = PoseEstimationMetrics(\n",
        "  num_joints = config['num_joints'],\n",
        "  oks_sigmas = config['oks_sigmas'],\n",
        "  max_objects_per_image = 30,\n",
        "  post_prediction_callback = post_prediction_callback,\n",
        ")\n",
        "\n",
        "trainer.test(model=best_model,\n",
        "            test_loader=test_dataloader,\n",
        "            test_metrics_list=metrics)"
      ],
      "metadata": {
        "id": "ZIVkrgLBTHTZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting with the best model"
      ],
      "metadata": {
        "id": "818sG2-UTjb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change for our model\n",
        "\n",
        "img_url = \"/content/drive/MyDrive/Dataset/valid\"\n",
        "best_model.predict(img_url, conf=0.20).show()"
      ],
      "metadata": {
        "id": "sfhBMKjZTlqk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}